{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L7psD4TcbTq",
        "outputId": "0b27668a-477e-4d31-bcb8-9bdef081b257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyfsl\n",
            "  Downloading easyfsl-1.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (2.2.2)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->easyfsl) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->easyfsl) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->easyfsl) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->easyfsl) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->easyfsl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->easyfsl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->easyfsl) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->easyfsl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.5.0->easyfsl) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->easyfsl) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->easyfsl) (3.0.2)\n",
            "Downloading easyfsl-1.5.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.8/72.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: easyfsl\n",
            "Successfully installed easyfsl-1.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install easyfsl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torchvision.models import resnet18\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "from easyfsl.samplers import TaskSampler\n",
        "from easyfsl.utils import plot_images, sliding_average"
      ],
      "metadata": {
        "id": "2y8VENnlcgEN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "image_size = 32  # CIFAR-100 image size\n",
        "N_WAY = 5  # Number of classes in a task\n",
        "N_SHOT = 5  # Number of images per class in the support set\n",
        "N_QUERY = 10  # Number of images per class in the query set\n",
        "N_EVALUATION_TASKS = 100\n",
        "N_TRAINING_EPISODES = 500"
      ],
      "metadata": {
        "id": "wDZ0-C0sc92W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-100 Dataset\n",
        "train_set = CIFAR100(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "            transforms.RandomCrop(image_size, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "        ]\n",
        "    ),\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "test_set = CIFAR100(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize([image_size, image_size]),\n",
        "            transforms.ToTensor(),\n",
        "        ]\n",
        "    ),\n",
        "    download=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi8TkzfmgzVL",
        "outputId": "9abc3f3f-1236-4b4d-cf1f-39ac72f43efb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:18<00:00, 9.16MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prototypical Networks\n",
        "class PrototypicalNetworks(nn.Module):\n",
        "    def __init__(self, backbone: nn.Module):\n",
        "        super(PrototypicalNetworks, self).__init__()\n",
        "        self.backbone = backbone\n",
        "\n",
        "    def forward(self, support_images: torch.Tensor, support_labels: torch.Tensor, query_images: torch.Tensor) -> torch.Tensor:\n",
        "        z_support = self.backbone(support_images)\n",
        "        z_query = self.backbone(query_images)\n",
        "\n",
        "        n_way = len(torch.unique(support_labels))\n",
        "        z_proto = torch.cat([z_support[support_labels == label].mean(0).unsqueeze(0) for label in range(n_way)])\n",
        "\n",
        "        dists = torch.cdist(z_query, z_proto)\n",
        "        scores = -dists\n",
        "        return scores\n",
        "\n",
        "convolutional_network = resnet18(pretrained=True)\n",
        "convolutional_network.fc = nn.Flatten()\n",
        "\n",
        "model = PrototypicalNetworks(convolutional_network).cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8mQckkogz-g",
        "outputId": "d3d17a24-e957-4b17-f830-1ed7b2b1a3a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 79.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test DataLoader\n",
        "test_set.get_labels = lambda: [instance[1] for instance in test_set]\n",
        "test_sampler = TaskSampler(test_set, n_way=N_WAY, n_shot=N_SHOT, n_query=N_QUERY, n_tasks=N_EVALUATION_TASKS)\n",
        "test_loader = DataLoader(test_set, batch_sampler=test_sampler, num_workers=12, pin_memory=True, collate_fn=test_sampler.episodic_collate_fn)\n",
        "\n",
        "# Training DataLoader\n",
        "train_set.get_labels = lambda: [instance[1] for instance in train_set]\n",
        "train_sampler = TaskSampler(train_set, n_way=N_WAY, n_shot=N_SHOT, n_query=N_QUERY, n_tasks=N_TRAINING_EPISODES)\n",
        "train_loader = DataLoader(train_set, batch_sampler=train_sampler, num_workers=12, pin_memory=True, collate_fn=train_sampler.episodic_collate_fn)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gt9wK8Ug5dc",
        "outputId": "78e01a08-8f42-4dd3-95d9-edc4bf46af66"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def fit(support_images: torch.Tensor, support_labels: torch.Tensor, query_images: torch.Tensor, query_labels: torch.Tensor) -> float:\n",
        "    optimizer.zero_grad()\n",
        "    classification_scores = model(support_images.cuda(), support_labels.cuda(), query_images.cuda())\n",
        "    loss = criterion(classification_scores, query_labels.cuda())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "wQewx_sNhSGT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "log_update_frequency = 10\n",
        "all_loss = []\n",
        "model.train()\n",
        "with tqdm(enumerate(train_loader), total=len(train_loader)) as tqdm_train:\n",
        "    for episode_index, (support_images, support_labels, query_images, query_labels, _) in tqdm_train:\n",
        "        loss_value = fit(support_images, support_labels, query_images, query_labels)\n",
        "        all_loss.append(loss_value)\n",
        "\n",
        "        if episode_index % log_update_frequency == 0:\n",
        "            tqdm_train.set_postfix(loss=sliding_average(all_loss, log_update_frequency))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlNKjZOfhSlL",
        "outputId": "86db0b9f-01a3-455d-d5ad-4623330b5447"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:38<00:00, 12.86it/s, loss=1.62]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def evaluate_on_one_task(support_images: torch.Tensor, support_labels: torch.Tensor, query_images: torch.Tensor, query_labels: torch.Tensor):\n",
        "    predicted_labels = torch.max(model(support_images.cuda(), support_labels.cuda(), query_images.cuda()).detach().data, 1)[1]\n",
        "    correct_predictions = (predicted_labels == query_labels.cuda()).sum().item()\n",
        "    return correct_predictions, len(query_labels), predicted_labels"
      ],
      "metadata": {
        "id": "n_xQt0nOhZca"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(data_loader: DataLoader):\n",
        "    total_predictions = 0\n",
        "    correct_predictions = 0\n",
        "    all_pred_labels = []\n",
        "    all_true_labels = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for episode_index, (support_images, support_labels, query_images, query_labels, class_ids) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "            correct, total, predicted_labels = evaluate_on_one_task(support_images, support_labels, query_images, query_labels)\n",
        "            total_predictions += total\n",
        "            correct_predictions += correct\n",
        "            all_pred_labels.extend(predicted_labels.cpu().numpy())\n",
        "            all_true_labels.extend(query_labels.cpu().numpy())\n",
        "\n",
        "    accuracy = (100 * correct_predictions / total_predictions)\n",
        "    precision = precision_score(all_true_labels, all_pred_labels, average='weighted')\n",
        "    recall = recall_score(all_true_labels, all_pred_labels, average='weighted')\n",
        "    f1 = f1_score(all_true_labels, all_pred_labels, average='weighted')\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Model tested on {len(data_loader)} tasks. Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "evaluate(test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZR0mbE7hcbx",
        "outputId": "4b37f23f-f502-4b2c-a3ea-706effeffcd8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "100%|██████████| 100/100 [00:02<00:00, 39.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model tested on 100 tasks. Accuracy: 37.22%\n",
            "Precision: 0.37\n",
            "Recall: 0.37\n",
            "F1 Score: 0.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}